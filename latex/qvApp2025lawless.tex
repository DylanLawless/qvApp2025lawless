\input{head.tex}
\usepackage[printonlyused,withpage,nohyperlinks]{acronym}
\begin{document}
% \linenumbers
%\raggedright

\newcounter{myboxcounter}
\newcommand{\boxlabel}[1]{%
  \refstepcounter{myboxcounter}%
  \label{#1}%
}

\title{Application of qualifying variants for genomic analysis}

% target: Bioinformatics https://academic.oup.com/bioinformatics/

\author[1]{Dylan Lawless\thanks{Addresses for correspondence: \href{mailto:Dylan.Lawless@uzh.ch}{Dylan.Lawless@kispi.uzh.ch}}}
\author[2]{Ali Saadat}
\author[2]{Mariam Ait Oumelloul}
\author[2]{Simon Boutry}
\author[1]{Veronika Stadler}
\author[3]{Sabine Österle}
\author[3]{Jan Armida}
\author[4]{David Haerry}
\author[5]{D. Sean Froese}
\author[1]{Luregn J. Schlapbach}
\author[2]{Jacques Fellay}
%\author[1]{Consortium Members}
\affil[1]{Department of Intensive Care and Neonatology, University Children's Hospital Zürich, University of Zürich, Switzerland.}
\affil[2]{Global Health Institute, School of Life Sciences, École Polytechnique Fédérale de Lausanne, Switzerland.}
\affil[3]{SPHN Data Coordination Center, SIB Swiss Institute of Bioinformatics, Basel, Switzerland.}
\affil[4]{Positive Council, Zürich, Switzerland.}
\affil[5]{Division of Metabolism and Children’s Research Center, University Children’s Hospital Zürich, University of Zurich, Zurich, Switzerland.}

\maketitle
\justify
% \tableofcontents
% \listoffigures
% \listoftables

\clearpage

\begin{abstract}
\noindent
\textbf{Motivation:} \\[1ex]
Qualifying variants (QVs) are genomic alterations selected by defined criteria within analysis pipelines. Although crucial for both research and clinical diagnostics, QVs are often seen as simple filters rather than dynamic elements that influence the entire workflow. 
In practice these rules are embedded within pipelines, which hinders transparency, audit, and reuse across tools. A unified, portable specification for QV criteria is needed.
\\[1ex]
\noindent
\textbf{Results:} \\[1ex]
Our aim is to embed the concept of a ``QV'' into the genomic analysis vernacular, moving beyond its treatment as a single filtering step. By decoupling QV criteria from pipeline variables and code, the framework enables clearer discussion, application, and reuse. It provides a flexible reference model for integrating QVs into analysis pipelines, improving reproducibility, interpretability, and interdisciplinary communication. Validation across diverse applications confirmed that QV based workflows match conventional methods while offering greater clarity and scalability.
\\[1ex]
\noindent
\textbf{Availability:} \\[1ex]
The source code and data are accessible at \url{https://github.com/DylanLawless/qv2025lawless}. The QV files and builder used in this work are available from \url{} the Zenodo repository). The QV framework is available under the MIT licence, and the dataset will be maintained for at least two years following publication.
\end{abstract}

\clearpage

\section*{Acronyms}
\renewenvironment{description}
{\list{}{\labelwidth0pt\itemindent-\leftmargin
    \parsep-1em\itemsep0pt\let\makelabel\descriptionlabel}}
               {\endlist}
\begin{acronym} 
 \acro{acat}[ACAT]{Aggregated Cauchy Association Test }
 \acro{acmg}[ACMG]{American College of Medical Genetics and Genomics}
 \acro{af}[AF]{Allele Frequency}
 \acro{ad}[AD]{Autosomal Dominant}
 \acro{ar}[AR]{Autosomal Recessive}
  \acro{cnv}[CNV]{Copy Number Variant}
  \acro{ehr}[EHR]{Electronic Health Record}
 \acro{fair}[FAIR]{Findable, Accessible, Interoperable, and Reusable}
 \acro{gatk}[GATK]{Genome Analysis Tool Kit}
  \acro{giab}[GIAB]{Genome in a Bottle}
 \acro{gwas}[GWAS]{Genome-Wide Association Study}
 \acro{indel}[INDEL]{Insertion / Deletion}
 \acro{iri}[IRI]{Internationalised Resource Identifier}
 \acro{hpo}[HPO]{Human Phenotype Ontology}
 \acro{maf}[MAF]{Minor Allele Frequency}
  \acro{md5}[MD5]{Message-Digest Algorithm 5}
  \acro{pca}[PCA]{Principal Component Analysis} 
 \acro{ppie}[PPIE]{Public and Patient Involvement and Engagement}
 \acro{prs}[PRS]{Polygenic Risk Score} 
 \acro{qc}[QC]{Quality Control}
 \acro{qv}[QV]{Qualifying Variant}
 \acro{rdf}[RDF]{Resource Description Framework}
 \acro{ax}[QV\textsubscript{ax}]{Axiomatic Variants}
 \acro{sf}[SF]{Secondary Findings}
 \acro{sha256}[SHA-256]{Secure Hash Algorithm 256}
 \acro{skat}[SKAT]{Sequence Kernel Association Test} 
 \acro{snv}[SNV]{Single Nucleotide Variant}
  \acro{snvindel}[SNV/INDEL]{Single Nucleotide Variant / Insertion Deletion}
  \acro{snomedct}[SNOMED CT]{Systematized Nomenclature of Medicine-Clinical Terms}
 \acro{snp}[SNP]{Single Nucleotide Polymorphism}
 \acro{sphn}[SPHN]{Swiss Personalized Health Network}
 \acro{uuid}[UUID]{Universally Unique Identifier}
 \acro{vcf}[VCF]{Variant Call Format}
  \acro{vep}[VEP]{Variant Effect Predictor}
 \acro{vqsr}[VQSR]{Variant Quality Score Recalibration}
 \acro{vsat}[VSAT]{Variant Set Association Test}
 \acro{vus}[VUS]{Variants of Unknown Significance}
 \acro{wes}[WES]{Whole Exome Sequencing}
 \acro{wgs}[WGS]{Whole Genome Sequencing}
\end{acronym}

\clearpage

\section{Introduction}
\label{sec:intro}
\ac{qv}s are genomic alterations selected by specific criteria within genome processing pipelines, serving as dynamic elements essential for both research and clinical diagnostics. 
\ac{qv}s are not merely static filters applied at a single step in an analysis pipeline; rather, they are dynamic, multifaceted elements that permeate the entire workflow, from initial data quality control to final result interpretation. This nuanced perspective underscores that \ac{qv}s play an integral role in shaping the fidelity and reproducibility of genomic analyses, enabling the iterative refinement of data and facilitating the integration of diverse analytical strategies throughout the pipeline.

Often, \ac{qv} selection adheres to established variant classification and reporting standards \cite{richards2015standards, li2017standards, li2017intervar, riggs2020technical, tavtigian2020fitting} and standardised workflows \cite{pedersen2021effective, anderson2010data, uffelmann2021genome}. 
However, a unified framework for \ac{qv}s is lacking, despite the recognised benefits of similar initiatives, such as \ac{prs} reporting standards \cite{wand2021improving, lambert2021polygenic}.
Tools such as vcfexpress \cite{pedersen_vcfexpress_2025} enable flexible filtering and formatting of \ac{vcf} files using user-defined expressions. Treating \ac{qv} criteria as an external parameter layer complements these tools by externalising their thresholds and logic. This approach improves reproducibility across distributed computing environments \cite{bal_programming_1989} and integrates seamlessly with workflow managers like Snakemake \cite{molder_sustainable_2021} or Nextflow \cite{di_tommaso_nextflow_2017}.

\ac{qv} selection criteria vary by application. In \ac{gwas}, thresholds favour common variants, yielding datasets with over 500{,}000 variants per subject, whereas rare disease analyses use stringent filters producing fewer than 1{,}000 variants, often limited to known genes or pathogenic loci. Although targeted filtering is valuable \cite{povysil2019rare, cirulli2015exome}, no unified approach exists. In practice, \ac{qv} sets range from broad quality control filters to specific disease panels, and their definition is critical for reproducibility and accurate reporting, influencing results as much as the pipeline itself \cite{olson2023variant}.

As \ac{wgs} becomes standard for large cohorts \cite{lee2018gene, jansen2019genome}, the integration of diverse \ac{qv} protocols is critical for data cleaning and analysis. 
During sequencing analysis several layers can be responsible for triggering \ac{qv} protocols, including
pre-existing metadata, technical \ac{qc} results, and post-calling annotations,
highlighting the need for a clear, unified approach. 

We introduce the \ac{qv} as a standalone entity, independent from other pipeline variables. Structured human- and machine-readable criteria, aligned with FAIR principles \cite{wilkinson2016fair}, facilitate integration across databases \cite{van2023bridging, toure2023fairification}. We advocate for the use of standard vocabularies, unique identifiers, and flexible file formats to support this integration.

Building on this framework, we propose an openly documented registry model for \ac{qv} files that assigns a unique \texttt{qv\_set\_id} and records a SHA-256 checksum for each release, enabling direct retrieval and verification for audit and re-analysis. Our accompanying HTML-based \ac{qv} builder converts simple \texttt{key=value} statements into structured YAML and can be embedded in public, private, or commercial websites to simplify the authoring of consistent criteria (Zenodo repository). The framework is designed to support the emergence of a shared, widely adopted registry over time.

\section{Methods}
\subsection{Implementation} \label{sec:framework}
The \ac{qv} file provides a structured, human- and machine-readable definition of variant qualifying criteria.
It is composed of five logical components that define its structure and metadata.
It is portable across tools, transparent in content, and verifiable through unique identifiers and checksums.
Each file is a lightweight YAML or JSON document specifying the variables and thresholds used in analysis. 
It can be read programmatically at runtime, for example using \texttt{yq} in shell-based workflows or \texttt{yaml::read\_yaml()} in R, providing the same parameters that would otherwise be embedded within pipeline configurations, as illustrated in \textbf{Figure~\ref{fig:qv_pipeline_with_file_vcurrent}}.
The output is identical to that of the native workflow, with the added benefit of an explicit, versioned, and shareable configuration file.

\begin{itemize}
    \item \textbf{1. Meta}: Descriptive metadata including \texttt{qv\_set\_id}, title, version, author list, creation date, and tags. These fields ensure traceability and version control across analyses.
    \item \textbf{2. Filters}: Simple rule-based statements that apply inclusion or exclusion logic based on variable thresholds (for example, minimum allele frequency or coverage depth). Filters can also restrict the analysis to defined genomic regions, such as a target gene panel or BED file.
    \item \textbf{3. Criteria}: Compound logic blocks that combine one or more conditions into interpretable rules, corresponding to concepts such as ACMG criteria or study-specific thresholds.
    \item \textbf{4. Notes}: Optional free-text annotations providing context, assumptions, or technical caveats.
    \item \textbf{5. Descriptions (optional)}: Plain-language fields, such as \texttt{description\_patient} and \texttt{description\_ppie}, that can record patient preferences or public involvement input. These complement the technical definitions without affecting computational logic.
\end{itemize}

\subsubsection*{Example QV structure}

We include an HTML-based \ac{qv} builder that can be embedded in research or commercial platforms to simplify the creation of consistent, versioned criteria files (available via Zenodo repository).   
A minimal \ac{qv} YAML file is shown in \textbf{Box \ref{box:qv_example}} , equivalent to the configuration generated by this builder.
QV files are composed of \texttt{key=value} statements, ensuring that all filtering and interpretation rules are explicit, versioned, and reproducible.
In simple terms, \textbf{Box \ref{box:qv_example}} specifies that only variants overlapping a curated disease gene panel are retained and that variants classified as pathogenic or likely pathogenic are prioritised.  
It also records patient context and patient-public involvement notes, thereby linking the technical filtering logic with its clinical and ethical rationale.

\begin{tcolorbox}[
    colback=white!0,
    colframe=black,
    boxrule=1pt,
    arc=1mm,
    outer arc=1mm,
    title=\textbf{\refstepcounter{myboxcounter}\label{box:qv_example}Box \themyboxcounter: qv\_disease\_panel\_example.yaml}
]
\begin{verbatim}
meta:
  qv_set_id: qv_disease_panel_v1_20250828
  version: 1.0.0
  title: Disease panel filter
filters:
  region_include:
    description: >
      Restrict to curated disease gene panel
    logic: keep_if
    field: OVERLAP(targets.disease_panel.bed)
    operator: '>='
    value: 1
criteria:
  pathogenic:
    description: >
      Variant classified as pathogenic or likely pathogenic
    logic: and
    conditions:
      - group: any_of:start
      - { field: CLASS, operator: '==', value: P }
      - { field: CLASS, operator: '==', value: LP }
      - group: any_of:end
meta:
  description_patient: >
    We have a strong family history of early heart attacks.
  description_ppie: >
    The PPIE group reviewed the criteria and approved them
    on 2025-08-15.
notes:
  - Gene panel file defines the target regions.
  - Additional quality filters may be added as needed.
\end{verbatim}
\end{tcolorbox}

\subsubsection*{FAIR mapping and patient involvement}

Each \ac{qv} file includes a persistent identifier (\texttt{qv\_set\_id}) that links criteria across analyses and databases. The framework aligns with the \ac{fair} principles of findability, accessibility, interoperability, and reusability \cite{wilkinson2016fair}. Findability is achieved through unique identifiers; accessibility through open, human- and machine-readable YAML or JSON files; interoperability through standardised syntax (i.e. \texttt{key=value}) and semantic mappings such as \ac{rdf} or \ac{snomedct} \cite{toure2023fairification, van2023bridging}; and reusability through embedded metadata, checksum verification, and versioned registry records.

Optional metadata fields such as \texttt{description\_patient} and \texttt{description\_ppie} allow patient input and \ac{ppie} feedback to be recorded in a manner appropriate to the study or application, with patient notes provided through consent-linked forms and  \ac{ppie} groups offering structured review or approval of criteria within the same \ac{fair}-compliant file.

\subsubsection*{Example QVs in WGS analysis}

A typical \ac{wgs} pipeline applies several \ac{qv} sets sequentially, as the genetic cause of disease may stem from different variant types such as SNVs, CNVs, or structural variants.  
Each pass filters data for its purpose, producing both cohort-level and single-patient results within one reproducible framework \cite{auwera_genomics_2020, li2025statistical}.  
As illustrated in
 \textbf{Figure~\ref{fig:qv_pipeline_with_file_vcurrent}}, the description can be written as:

``A cohort of patient WGS data was analysed to identify genetic determinants for phenotype X. A flexible \ac{qv} set was applied using the 
\colorbox{colorSUNSET1!10}{\texttt{pipeline v1}}, which implements the \colorbox{colorSUNSET2!20}{\texttt{QV\_SNV\_INDEL\_1}} criteria to produce the prepared dataset (\colorbox{colorSUNSET3!10}{\texttt{dataset v1}}). This dataset was analysed alongside other modules (e.g. \colorbox{colorSUNSET4!10}{\texttt{PCA\_SNV\_INDEL\_v1}} and \colorbox{colorSUNSET5!10}{\texttt{statistical\_genomics\_v1}}) to derive a cohort-level association signal (Result 1). It was then re-filtered with stricter \colorbox{colorSUNSET2!20}{\texttt{QV\_SNV\_INDEL\_2}} criteria to identify known causal variants, yielding (\colorbox{colorSUNSET3!10}{\texttt{dataset v2}}) and single-patient reports (Result 2).''

\begin{tcolorbox}[
    colback=white!0,
    colframe=black,
    boxrule=1pt,
    arc=1mm,
    outer arc=1mm,
    title=\textbf{\refstepcounter{myboxcounter}\label{box:pipe}Box \themyboxcounter: Example diagrammatic representation}
]
\dirtree{%
.1 \colorbox{colorSUNSET1!10}{\texttt{pipeline v1}}.
.2 Flexible \ac{qv} criteria.
.3 \colorbox{colorSUNSET2!20}{\texttt{QV\_SNV\_INDEL\_1}} $\rightarrow$ \colorbox{colorSUNSET3!10}{\texttt{dataset v1}}.
.4 \colorbox{colorSUNSET4!10}{\texttt{PCA\_SNV\_INDEL\_v1}}.
.4 \colorbox{colorSUNSET5!10}{\texttt{statistical\_genomics\_v1}} $\rightarrow$ Result 1.
.3 \colorbox{colorSUNSET3!10}{\texttt{dataset v1}}.
.4 Rare disease \ac{qv} criteria.
.5 \colorbox{colorSUNSET2!20}{\texttt{QV\_SNV\_INDEL\_2}} $\rightarrow$ \colorbox{colorSUNSET3!10}{\texttt{dataset v2}}.
.6 \colorbox{colorSUNSET5!10}{\texttt{single case report SNV INDEL v1}} $\rightarrow$ Result 2.
.3 Joint analysis output.
}
\medskip

Joint analysis output from:\\
Result 1 = Cohort-level association signal (e.g. variant P-value).\\
Result 2 = Single variant report per patient.
\end{tcolorbox}

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{./images/qv_pipeline_with_file_vcurrent.pdf}
\caption{Summary of the QV application for a WGS pipeline. \ac{qv}1 and \ac{qv}2 are applied as sequential protocol steps. In this example, \ac{qv}2 differs from \ac{qv}1 by retaining only likely/pathogenic variants (indicated by a red X). The QV file loaded by the analysis pipeline comprises a description field (optional) and a variables field (mandatory). The \ac{qv} criteria may be distributed across multiple pipeline steps.}
\label{fig:qv_pipeline_with_file_vcurrent}
\end{figure}

\subsection{Usage in a rare disease cohort validation study}

We validated the \ac{qv} framework on an in-house rare disease cohort of 940 individuals using \ac{wes} comparing a conventional manual implementation with a \ac{qv}-based YAML configuration. The analysis targeted rare variants (\ac{maf}~$<0.01$) in known disease genes from the Genomics England ``Primary immunodeficiency or monogenic inflammatory bowel disease'' panel, retrieved via PanelAppRex \cite{lawless_panelapprex_2025}. This yielded 6{,}026 candidate variants annotated with 376 information sources, prepared in R using the GuRu variant interpretation tool and imported from gVCF files processed by \ac{vep}.

We applied the first eight \ac{acmg} criteria for pathogenicity scoring \cite{richards2015standards}, six of which were relevant to this cohort. The manual pipeline encoded each criterion directly, while the \ac{qv} workflow read the same definitions from a YAML file. % Both produced identical outputs. 
The YAML criteria included \texttt{ACMG\_PS1} (known pathogenic amino acid change), \texttt{ACMG\_PS3} (supporting functional evidence), \texttt{ACMG\_PS5} (compound heterozygosity), and frequency- and segregation-based criteria (\texttt{PM2}, \texttt{PM3}). Criteria \texttt{PS2} and \texttt{PS4} were not applicable in this cohort.

\subsection{Usage in a GWAS validation study}
We next applied the \ac{qv} criteria framework to a \ac{gwas} using HapMap3 Phase 3 (R3) consensus genotypes on 1397 individuals \cite{2020fairleyInternationalGenomeSample}. Again, two pipelines were executed with identical inputs and parameters: one hard-coded and one driven by the \ac{qv}  file.
%``qv\_gwas\_common\_v1\_20250826.yaml'' (Zenodo). 
This \ac{qv}  set defined common GWAS thresholds: restriction to autosomal, biallelic SNPs; minimum sample call rate of $95\%$; variant call rate of $95\%$; minor allele frequency $\geq 1\%$; and Hardy–Weinberg equilibrium $p \geq 1\times10^{-6}$. After quality control, variants were LD-pruned and principal components (PC1–PC10) were computed, with sex included as an additional covariate. Logistic regression under an additive model was then performed with a binary simulated phenotype using PLINK.
The outputs of the two pipelines were captured and compared across each main PLINK stage. Manhattan plots, \ac{pca} plots, and \texttt{md5} checksums were used to confirm exact reproducibility between the hard-coded and QV-driven analyses.

For benchmarking, \ac{md5} checksums were uniquely reported for the GWAS study because PLINK output files are exactly reproducible between runs. In contrast, VCF files used in the other validation studies include variable header fields such as BCFtools view command with a timestamp, which changes with each run and alters the \ac{md5} value. For those cases, we instead report variant count and content.

\subsection{Usage in a WGS validation study with GIAB and Exomiser}
We next applied the \ac{qv} framework to a \ac{wgs} trio analysis using the Genome In A Bottle Chinese Trio (HG005-HG007, PRJNA200694, GRCh38 v4.2.1) of the National Institute of Standards and Technology \cite{2022wagnerBenchmarkingChallengingSmall}. 
Two pipeline phases were executed with identical inputs and parameters: one hard-coded and one driven by the \ac{qv} file.
Both phases applied identical \ac{qc} and study filters and included a gene-panel style analysis using the paediatric disorders panel (panel 486; 3{,}853 genes \cite{lawless_panelapprex_2025}). 
The upstream processing used BCFtools for region restriction using BED overlap, site-level thresholds on QUAL and INFO/DP (using computed site depth from per-sample FORMAT/DP when absent), and per-sample thresholds on FORMAT/DP and FORMAT/GQ with exclusion of missing genotypes. 
Composite criteria were applied to require either all samples to pass or at least one sample to pass. 
The downstream filtered trio \ac{vcf} was analysed with Exomiser using the same trio \texttt{.ped} input and without using \ac{hpo} terms.

\section{Results}
\subsection{Validation rare disease cohort case study}
We validated the \ac{qv} framework using \ac{wes} analysis with \ac{acmg}-based criteria on a rare disease cohort of 940 individuals, comparing a conventional pipeline with parameters defined internally (QV manual) to the new external YAML-based implementation (QV yaml).
As shown in \textbf{Figure \ref{fig:guru_singlecase_validation_of_yaml_vs_manual}}, 
the outputs from both methods were identical, demonstrating a 100\% match. This confirmed that our framework of a standalone, shareable, \ac{qv} criteria file can be imported and applied programmatically with equivalent accuracy, providing a reproducible resource that is adaptable across different pipelines and programming environments.

\subsection{Validation in a common variant GWAS}
To demonstrate the integration of the \ac{qv} framework with established best practices in \ac{gwas} \cite{2021uffelmannGenomewideAssociationStudies}, we validated it in a standard HapMap3 Phase 3 \ac{gwas} by again running two equivalent analyses: a conventional pipeline with parameters defined internally and a YAML-based implementation that externalised all settings.
As shown in \textbf{Figure~\ref{fig:hapmap_gwas_validation}}, the Manhattan and \ac{pca} plots were identical between the two methods, and the \ac{md5} checksums of all PLINK outputs matched exactly. These results confirm that \ac{qv} parameterisation reproduces the original workflow precisely while improving clarity, transparency, and reusability.

\subsection{Validation in a WGS study with GIAB and Exomiser}
To demonstrate the ease and benefit of using \ac{qv} parameterisation in established \ac{wgs} analysis pipelines, we conducted a trio validation study using the \ac{giab} Chinese Trio (HG005-HG007, GRCh38 v4.2.1) and the Exomiser tool for variant annotation and interpretation \cite{2020ciprianiImprovedPhenotypeDrivenTool}. 
Two equivalent analyses were run: one with hard-coded thresholds and one using an external \ac{qv} YAML file specifying the same parameters. Both applied identical \ac{qc} and study filters and restricted analysis to the PanelAppRex paediatric disorders panel (3{,}853~genes). Results were identical: variant counts matched at each step, and Exomiser outputs produced the same candidate genes and variants. \textbf{Figure~\ref{fig:qv_exomiser_validation}} shows this agreement.
This validation confirms that a shareable \ac{qv} file reproduces the full variant interpretation workflow exactly, while aligning with established variant effect predictors and interpretation tools \cite{2024riccioVariantEffectPredictors, 2020ciprianiImprovedPhenotypeDrivenTool, 2020holtgreweVarFishComprehensiveDNA}.
Benchmarking showed that QV files introduce no computational overhead and scale equivalently to conventional implementations 
(\textbf{Supplemental \ref{sec:benchmark}}, 
\textbf{Figure \ref{fig:benchmark_preprocess_time_bars_by_step_elapsed}}).

\subsection{Implications}
\subsubsection*{General applicability and reproducibility}
Across validation studies, the \ac{qv} framework reproduced conventional workflows in which parameters are embedded within scripts, while externalising those same variables into a portable, shareable format. The framework itself performs no filtering, calling, annotation, or interpretation, but provides a machine-readable layer for defining and reusing the qualifying variables that underpin these analyses. It complements tools such as GATK and BCFtools for processing, Ensembl VEP, SnpEff, FAVOR, and WGSA for variant effect prediction \cite{2024riccioVariantEffectPredictors}, and Exomiser and VarFish for interpretation \cite{2020ciprianiImprovedPhenotypeDrivenTool, 2020holtgreweVarFishComprehensiveDNA}, by making their analytic criteria explicit.

\subsubsection*{Scalability and interoperability with genomic tools}
The validation studies, covering clinical interpretation, genome-wide association analysis, and WGS trio interpretation, demonstrate that the \ac{qv} framework generalises across distinct genomic contexts without altering analytical outcomes or adding computational overhead. The format further allows users to define, combine, and extend their own \ac{qv} sets using simple declarative syntax, providing a scalable approach for reproducible genomics.

\subsubsection*{Traceability and confirmation of applied clinical standards}
Each \ac{qv} file includes a persistent identifier and checksum that can be stored in \ac{ehr} or laboratory systems such as EPIC, Cerner, Clinisys, or REDCap. This links each patient’s analysis (including any associated \ac{ppie} input) to the exact \ac{qv} set used, enabling transparent, auditable, and \ac{fair}-compliant reporting.  
A clinician or molecular pathologist viewing a result in EPIC or Cerner can access the linked \texttt{qv\_set\_id} to verify the applied standards and filtering criteria. Automated genomic reports should include these details by default, ensuring full traceability without requiring access to the pipeline.  
For example, if a patient asks whether their genome was screened for breast cancer due to variants in \textit{BRCA1} or \textit{BRCA2}, the \ac{ehr}-linked report referencing ``qv acmg sf v3.3 20250828.json'' confirms that the \ac{acmg} secondary findings guideline (v3.3) \cite{miller2023acmg} was applied, including its defined gene set, thresholds, version, and standard.  

\section{Summary}
This paper introduces a framework for integrating qualifying variants into genomic analysis pipelines, enhancing reproducibility, interpretability and the seamless translation of research findings into clinical practice.

\FloatBarrier

\section{Funding}
This project was supported through the grant Swiss National Science Foundation  320030\_201060, and NDS-2021-911 (SwissPedHealth) from the Swiss Personalized Health Network and the Strategic Focal Area `Personalized Health and Related Technologies' of the ETH Domain (Swiss Federal Institutes of Technology).

\section{Acknowledgements}
Acknowledgements We would like to thank all the patients and families who have been providing advice on SwissPedHealth and its projects, as well as the clinical and research teams at the participating institutions.

\section{Contributions}
DL designed the work and contributed to the manuscript.
AS, SB, VS, DH, SÖ, JA, SF contributed to the manuscript.
LJS and JF supervised the work, manuscript, and applied for funding.

\section{Competing interests}
The authors declare no competing interests.

\section{Ethics statement}
The projects were approved by the respective ethics committees of all participating centers (Cantonal Ethics Committee Bern, approval number KEK-029/11) and the study was conducted in accordance with the Declaration of Helsinki.

\bibliographystyle{unsrtnat}
\bibliography{references} 
\clearpage
\FloatBarrier

%\\\\\\\\\\\\\\\\\\\\\\\\\\\\
\beginsupplement
\section{Supplemental} \label{Supplemental_text}
\textbf{Application of qualifying variants for genomic analysis.}

\subsection{Validation study figures}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{./images/Guru_singlecase_validation_of_yaml_vs_manual.pdf}
\caption{Validation case study of a rare disease cohort of 940 WES individuals using an \ac{acmg} criteria subset, demonstrating a 100\% match between manually encoded and standalone YAML-based \ac{qv} for assigning pathogenicity scores.}
\label{fig:guru_singlecase_validation_of_yaml_vs_manual}
\end{figure}


\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./images/hapmap_gwas_validation.pdf}
\caption{Validation in GWAS using QV parameterisation. 
(A) \ac{gwas} of simulated binary phenotypes in HapMap3 Phase 3 (R3) using a traditional variable embedded pipeline. Shown are the Manhattan plot of logistic regression results (left) and correction for population structure with principal component analysis (PC1 vs PC2, right). 
(B) Identical \ac{gwas} using a \ac{qv} YAML configuration file. The Manhattan and PCA results are indistinguishable from panel~A. 
(C) Verification of reproducibility. MD5 checksums of the main PLINK outputs are identical between panels~A and~B. The steps included processing of autosomal biallelic SNPs, sample call rate, variant call rate, minor allele frequency, Hardy–Weinberg equilibrium, and association results. The QV file encoded these thresholds (sample call rate $\geq$95\%, variant call rate $\geq$95\%, MAF $\geq$1\%, HWE p~$\geq$1e-6, autosomal biallelic SNPs only) together with covariates (sex and PC1-PC10) and logistic regression settings. This confirms that a shareable QV file reproduces hard-coded pipelines exactly while improving transparency and reusability.
}
    \label{fig:hapmap_gwas_validation}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./images/qv_exomiser/exomiser_validation_bars_facet_metric.pdf}
\caption{Validation of the trio Exomiser pipeline using \ac{qv} parameterisation. 
\textbf{(A)} summarises upstream processing counts by file, 
\textbf{(B)} compares downstream Exomiser metrics, 
and \textbf{(C)} shows the key variant fields for the two variants identified. 
Variant counts in all panels confirm that intermediate files and final outputs are identical between configurations. 
The five preprocessing stages shown in~(A) are: 
(0) input trio VCF, (1) gene panel region and quality filtering, (2) tag annotation, (3) site-level depth range filtering, and (4) final QC-filtered VCF. 
MOI, mode of inheritance; HGVS, Human Genome Variation Society nomenclature.}
\label{fig:qv_exomiser_validation}
\end{figure}

\FloatBarrier
\subsection{Computational benchmark}\label{sec:benchmark}
Runtime performance was equivalent between traditional and \ac{qv}-based pipelines, as both read identical parameters from different sources. In the WGS trio validation study, pre-processing steps including filtering, \ac{qc}, and gene panel selection completed in 16–17~seconds, with a median difference of \textasciitilde0.5~seconds favouring the \ac{qv} YAML pipeline (\textbf{Figure \ref{fig:benchmark_preprocess_time_bars_by_step_elapsed}}). An incidental one-off 5~second delay arose from Singularity initialisation for the \texttt{yq} utility (step~0), a system-specific effect on our HPC and unrelated to the framework itself.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./images/qv_exomiser/benchmark_preprocess_time_bars_by_step_elapsed.pdf}
\caption{Benchmark of upstream preprocessing times in the WGS trio pipeline comparing \ac{qv}-based and traditional (manually parameterised) configurations. Stepwise elapsed times were nearly identical across both methods (median difference \textasciitilde0.5~s), with a fixed 5~s overhead from optional Singularity initialisation of \texttt{yq} in the \ac{qv} pipeline. The four preprocessing steps correspond to: (1) gene panel region and quality filtering of the trio VCF, (2) annotation of variant tags, (3) site-level depth range filtering, and (4) per-sample genotype filtering and exclusion of missing genotypes. All steps used \texttt{BCFtools} on VCF preprocessing, as illustrated in \textbf{Figure~\ref{fig:qv_exomiser_validation} (A)}.}
\label{fig:benchmark_preprocess_time_bars_by_step_elapsed}
\end{figure}

\end{document}
